# -*- coding: utf-8 -*-
"""Models Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19gNo4kT2HHXdofeyn_DXtL8AP-2eYr4T
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.cm as cm
import pandas as pd
import pandas_datareader as web
import datetime as dt
import os
import math
from itertools import product
import warnings
warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM, SimpleRNN, Embedding
from tensorflow.keras.utils import to_categorical
import tensorflow.keras.backend as K
import tensorflow as tf
from sklearn.svm import SVR, SVC
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, classification_report, accuracy_score, precision_recall_curve, confusion_matrix
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.utils.class_weight import compute_class_weight
from sklearn.preprocessing import label_binarize
from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix



"""# Data Import"""

d22 = pd.read_excel('/content/drive/MyDrive/קורס למידה חישובית/Project/dat start build bniya_2022.xlsx')
d23 = pd.read_excel('/content/drive/MyDrive/קורס למידה חישובית/Project/dat start build bniya_2023.xlsx')

df = d22.merge(
    d23[['BinyanID', 'TaarichHathala']],
    on='BinyanID',
    how='left',
    suffixes=('_2022', '_2023')).drop_duplicates()
print(f'obs: {df.shape[0]}')

df = df[df['shnath']<=2022]
print(f'obs up to 2022: {df.shape[0]}')

# define TaarichHathala
df['TaarichHathala'] = df['TaarichHathala_2022']
df.loc[df['TaarichHathala'].isna(),'TaarichHathala'] = df.loc[df['TaarichHathala'].isna(),'TaarichHathala_2023']

# remove obs without TaarichHathala
df = df[~df['TaarichHathala'].isna()]
print(f'obs with TaarichHathala : {df.shape[0]}')

# create y = month diff between TaarichHathala to TaarichHeter
# keep obs with y>=0
df['TaarichHathala'] = pd.to_datetime(df['TaarichHathala'])
df['TaarichHeter'] = pd.to_datetime(df['TaarichHeter'])
df['y'] = df['TaarichHathala'].dt.to_period('M').astype(int) - df['TaarichHeter'].dt.to_period('M').astype('int64')
df = df.loc[df['y']>=0]
print(f'obs with y>=0 : {df.shape[0]}')

# fix variable values
df.loc[df.CodMahoz>=7, 'CodMahoz'] = 7
df.loc[df.lemecira>1, 'lemecira'] = 0
df.loc[df.matarasibsud>1, 'matarasibsud'] = 0
df.loc[df.tama_pinuybinuy>1, 'tama_pinuybinuy'] = 0

bins1 = [0,4,7,10,13,16,19, np.inf]
labels1 = ['0-3','4-6','7-9','10-12','13-15','16-18','19+']
bins2 = list(range(0, 20)) + [np.inf]
labels2 = list(range(0, 20))

df['y1'] = pd.cut(df['y'], bins=bins1, labels=labels1, right=False)
df['y2'] = pd.cut(df['y'], bins=bins2, labels=labels2, right=False)

# convert categories to codes
df['y1'] = df['y1'].cat.codes
df['y2'] = df['y2'].cat.codes

df_train, df_test = train_test_split(df, test_size=0.25, random_state=123)

s1 = df_train[df_train['TaarichHathala_2022'].isna()].shape[0]
s2 = df_test[df_test['TaarichHathala_2022'].isna()].shape[0]

print('train obs: {}, train obs from 2023 data: {} ({:.0f}%)'.
      format(df_train.shape[0],s1, 100. * s1/df_train.shape[0]))
print('test obs: {}, test obs from 2023 data: {} ({:.0f}%)'.
      format(df_test.shape[0],s2, 100. * s2/df_test.shape[0]))

x_cols = ['lemecira', 'matarasibsud', 'tama_pinuybinuy', 'mspdirot_matarot','MspKomot', 'ShetahBinyan', 'ShetahDirot','chodeshh','CodMahoz']
y_cols = ['y','y1','y2']

X_train = df_train[x_cols]
Y_train = df_train[y_cols]
X_test = df_test[x_cols]
Y_test = df_test[y_cols]

# processing X

# Identify the columns
indicator_cols = [0, 1, 2]  # Columns for indicator variables
continuous_cols = [3, 4, 5, 6]  # Columns for continuous variables
categorical_col = [7, 8]  # Column for the categorical variable

preprocessor = ColumnTransformer(
    transformers=[
        ('indicators', 'passthrough', indicator_cols),
        ('scaler', StandardScaler(), continuous_cols),  # Use StandardScaler
        ('encoder', OneHotEncoder(), categorical_col)
    ]
)

X_train_processed = preprocessor.fit_transform(X_train)
ohe = preprocessor.named_transformers_['encoder']
column_names = list(X_train.columns[indicator_cols]) + \
               list(X_train.columns[continuous_cols]) + \
                list(ohe.get_feature_names_out(X_train.columns[categorical_col]))
X_train_processed = pd.DataFrame(X_train_processed, columns=column_names)

X_test_processed = preprocessor.fit_transform(X_test)
X_test_processed = pd.DataFrame(X_test_processed, columns=column_names)



"""# SVM"""

def calculate_class_weights(y):
    class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)
    return dict(enumerate(class_weights))


# SVR (regression)
def svm_model_regression(X_tr, X_ts, Y_tr, Y_ts, param_grid):
    svm_pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('svm', SVR())
    ])
    grid_search = GridSearchCV(svm_pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')
    grid_search.fit(X_tr, Y_tr)
    print("Best parameters found:", grid_search.best_params_)

    y_pred = grid_search.best_estimator_.predict(X_ts)
    mse = mean_squared_error(Y_ts, y_pred)
    print(f'RMSE (Regression): {math.sqrt(mse)}')

# SVC (classification)
def svm_model_classification(X_tr, X_ts, Y_tr, Y_ts, param_grid, class_weights=None):
    svm_pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('svm', SVC(class_weight=class_weights, probability=True))
    ])
    grid_search = GridSearchCV(svm_pipeline, param_grid, cv=2, scoring='accuracy')
    grid_search.fit(X_tr, Y_tr)
    print("Best parameters found:", grid_search.best_params_)

    y_pred = grid_search.best_estimator_.predict(X_ts)
    y_prob = grid_search.best_estimator_.predict_proba(X_ts)

    acc = accuracy_score(Y_ts, y_pred)
    print(f'Accuracy Score: {acc}')
    print(classification_report(Y_ts, y_pred))

    # Compute precision-recall curve
    y_ts_bin = label_binarize(Y_ts, classes=np.unique(Y_ts))
    precision, recall, _ = precision_recall_curve(y_ts_bin.ravel(), y_prob.ravel())
    return [precision, recall]

## SVR
param_grid_svr = {
    'svm__C': [0.1, 1, 10, 100],      # Regularization parameter
    'svm__epsilon': [0.1, 0.2, 0.5],  # Epsilon in the epsilon-insensitive loss
    'svm__kernel': ['linear', 'rbf'],  # Type of kernel
    'svm__gamma': ['scale', 'auto']   # Kernel coefficient
}
svm_model_regression(X_train_processed, X_test_processed, Y_train['y'], Y_test['y'], param_grid_svr)

## SVC
param_grid_svc = {
    'svm__C': [0.1, 1, 10, 100],       # Regularization parameter
    'svm__gamma': [0.1, 1, 10, 100], # Kernel coefficient
    'svm__kernel': ['linear', 'rbf', 'poly'],  # Type of kernel
    'svm__class_weight': [None, 'balanced']  # Weights for classes
}

y1_w = calculate_class_weights(Y_train['y1'])
svm_y1 = svm_model_classification(X_train_processed, X_test_processed, Y_train['y1'], Y_test['y1'], param_grid_svc, y1_w)

y2_w = calculate_class_weights(Y_train['y2'])
svm_y2 = svm_model_classification(X_train_processed, X_test_processed, Y_train['y2'], Y_test['y2'], param_grid_svc, y2_w)

## Plot precision-recall curve
def plot_precision_recall(precision,recall,title):
  plt.figure(figsize=(3,3))
  plt.plot(recall, precision,linestyle='-', color='#5997f7', linewidth=1)
  plt.title(title, fontsize=10)
  plt.xlabel('Recall', fontsize=9)
  plt.ylabel('Precision', fontsize=9)
  plt.xticks(fontsize=8)
  plt.yticks(fontsize=8)
  plt.show()


plot_precision_recall(svm_y1[0],svm_y1[1],"7 Classes SVM")
plot_precision_recall(svm_y2[0],svm_y2[1],"20 Classes SVM")

"""# NN"""

# Ensure all features are float32
X_train_processed = X_train_processed.astype('float32')
X_test_processed = X_test_processed.astype('float32')

# For regression, the target should also be float32
Y_train['y'] = Y_train['y'].astype('float32')
Y_test['y'] = Y_test['y'].astype('float32')

Y_train = Y_train.rename(columns={'y': 'regression', 'y1': 'multi-class', 'y2': 'ordinal'})
Y_test = Y_test.rename(columns={'y': 'regression', 'y1': 'multi-class', 'y2': 'ordinal'})


# Convert data to PyTorch tensors
X_train_tensor = torch.FloatTensor(X_train_processed.values)
X_test_tensor = torch.FloatTensor(X_test_processed.values)

Y_train_regression = torch.FloatTensor(Y_train['regression'].values).unsqueeze(1)
Y_test_regression = torch.FloatTensor(Y_test['regression'].values).unsqueeze(1)

Y_train_multiclass = torch.LongTensor(Y_train['multi-class'].values)
Y_test_multiclass = torch.LongTensor(Y_test['multi-class'].values)

Y_train_ordinal = torch.LongTensor(Y_train['ordinal'].values)
Y_test_ordinal = torch.LongTensor(Y_test['ordinal'].values)

# Define the neural network model
class NeuralNetwork(nn.Module):
    def __init__(self, input_size, hidden_sizes, output_size, activation_func):
        super(NeuralNetwork, self).__init__()
        layers = []
        prev_size = input_size
        for hidden_size in hidden_sizes:
            layers.append(nn.Linear(prev_size, hidden_size))
            if activation_func == 'relu':
                layers.append(nn.ReLU())
            elif activation_func == 'tanh':
                layers.append(nn.Tanh())
            prev_size = hidden_size
        layers.append(nn.Linear(prev_size, output_size))
        self.model = nn.Sequential(*layers)

    def forward(self, x):
        return self.model(x)

# Training function
def train_model(model, criterion, optimizer, train_loader, num_epochs):
    losses = []
    for epoch in range(num_epochs):
        for inputs, targets in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
        losses.append(loss.item())
    return losses

# Evaluation function
def evaluate_model(model, X, y, task):
    model.eval()
    with torch.no_grad():
        predictions = model(X)
        if task == 'regression':
            mse = mean_squared_error(y, predictions)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y, predictions)
            return mse, rmse, mae
        else:
            _, predicted = torch.max(predictions, 1)
            accuracy = accuracy_score(y, predicted)
            error_rate = 1 - accuracy
            return error_rate, accuracy

# Parameter lists
learning_rate_list = [0.001, 0.01, 0.1]
activation_func_list = ['relu', 'tanh']
number_layers_list = [1, 3, 5,10]

# Results storage
results = {
    'regression': [],
    'multi-class': [],
    'ordinal': []
}

# Train and evaluate models for each parameter combination
for task in ['regression', 'multi-class', 'ordinal']:
    for lr, act_func, num_layers in product(learning_rate_list, activation_func_list, number_layers_list):
        input_size = X_train_tensor.shape[1]
        hidden_sizes = [64] * num_layers

        if task == 'regression':
            output_size = 1
            criterion = nn.MSELoss()
            Y_train = Y_train_regression
            Y_test = Y_test_regression
        elif task == 'multi-class':
            output_size = len(torch.unique(Y_train_multiclass))
            criterion = nn.CrossEntropyLoss()
            Y_train = Y_train_multiclass
            Y_test = Y_test_multiclass
        else:  # ordinal
            output_size = len(torch.unique(Y_train_ordinal))
            criterion = nn.CrossEntropyLoss()
            Y_train = Y_train_ordinal
            Y_test = Y_test_ordinal

        model = NeuralNetwork(input_size, hidden_sizes, output_size, act_func)
        optimizer = optim.Adam(model.parameters(), lr=lr)

        train_dataset = TensorDataset(X_train_tensor, Y_train)
        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

        losses = train_model(model, criterion, optimizer, train_loader, num_epochs=50)

        if task == 'regression':
            mse, rmse, mae = evaluate_model(model, X_test_tensor, Y_test.numpy(), task)
            results[task].append({
                'lr': lr,
                'activation': act_func,
                'num_layers': num_layers,
                'mse': mse,
                'rmse': rmse,
                'mae': mae,
                'losses': losses,
                'model': model
            })
        else:
            error_rate, accuracy = evaluate_model(model, X_test_tensor, Y_test.numpy(), task)
            results[task].append({
                'lr': lr,
                'activation': act_func,
                'num_layers': num_layers,
                'error_rate': error_rate,
                'accuracy': accuracy,
                'losses': losses,
                'model': model
            })

# Plot loss functions
for task in results:
    plt.figure(figsize=(12, 8))
    for result in results[task]:
        label = f"lr={result['lr']}, act={result['activation']}, layers={result['num_layers']}"
        plt.plot(result['losses'], label=label)
    plt.title(f'Loss Function for {task.capitalize()} Task')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()



# Find best models and plot their loss functions
best_models = {}
for task in results:
    if task == 'regression':
        best_model = min(results[task], key=lambda x: x['rmse'])
    else:
        best_model = max(results[task], key=lambda x: x['accuracy'])
    best_models[task] = best_model

    # Plot loss function for the best model
    plt.figure(figsize=(10, 6))
    plt.plot(best_model['losses'])
    plt.title(f'Loss Function for Best {task.capitalize()} Model')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.grid(True)

    # Add text with model details
    text = f"Learning rate: {best_model['lr']}\n"
    text += f"Activation function: {best_model['activation']}\n"
    text += f"Number of layers: {best_model['num_layers']}\n"
    if task == 'regression':
        text += f"Best RMSE: {best_model['rmse']:.4f}"
    else:
        text += f"Best Accuracy: {best_model['accuracy']:.4f}"

    plt.text(0.05, 0.95, text, transform=plt.gca().transAxes, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

    plt.tight_layout()
    plt.show()

    # Generate and save predictions
    best_model['model'].eval()
    with torch.no_grad():
        if task == 'regression':
            y_pred_reg = best_model['model'](X_test_tensor).numpy().flatten()
            y_true = Y_test_regression.numpy().flatten()

        elif task == 'multi-class':
            y_pred_multi = best_model['model'](X_test_tensor).argmax(dim=1).numpy()
            y_true = Y_test_multiclass.numpy()
            print("best model multi class report")
            print(sklearn.metrics.classification_report(y_true, y_pred_multi))
        else:  # ordinal
            y_pred_ordinal = best_model['model'](X_test_tensor).argmax(dim=1).numpy()
            y_true = Y_test_ordinal.numpy()
            print("best model ordinal  report")
            print(sklearn.metrics.classification_report(y_true, y_pred_ordinal))






# Print best models
for task, model in best_models.items():
    print(f"\nBest model for {task}:")
    print(f"Learning rate: {model['lr']}")
    print(f"Activation function: {model['activation']}")
    print(f"Number of layers: {model['num_layers']}")
    if task == 'regression':
        print(f"RMSE: {model['rmse']:.4f}")
    else:
        print(f"Accuracy: {model['accuracy']:.4f}")


# Plot predicted vs real values for best regression model
best_regression_model = best_models['regression']['model']
best_regression_model.eval()

with torch.no_grad():
    y_pred = best_regression_model(X_test_tensor).numpy().flatten()
    #y_pred_reg = y_pred
    y_true = Y_test_regression.numpy().flatten()

plt.figure(figsize=(10, 6))
plt.scatter(y_true, y_pred, alpha=0.5)
plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.title('Predicted vs True Values (Regression)')
plt.show()

# Print confusion matrices for best multi-class and ordinal models
for task in ['multi-class', 'ordinal']:
    best_model = best_models[task]['model']
    best_model.eval()

    with torch.no_grad():
        y_pred = best_model(X_test_tensor).argmax(dim=1).numpy()
        if task == 'multi-class':
            y_true = Y_test_multiclass.numpy()
            #y_true_multi = y_true
        else:  # ordinal
            y_true = Y_test_ordinal.numpy()
            #y_true_ordinal = y_true

    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix for {task.capitalize()} Task')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()


y_pred_all = pd.DataFrame({
    'y_real_real_reg': Y_test_regression.numpy().flatten(),
    'y_pred_reg': y_pred_reg,
    'y_true_multi': Y_test_multiclass.numpy(),
    'y_pred_multi': y_pred_multi,
    'y_true_ordinal': Y_test_ordinal.numpy(),
    'y_pred_ordinal': y_pred_ordinal
})

# Apply SMOTE to the multi-class and ordinal targets
smote = SMOTE(random_state=42)

X_train_multiclass_resampled, y_train_multiclass_resampled = smote.fit_resample(X_train_processed, Y_train['multi-class'])
X_train_ordinal_resampled, y_train_ordinal_resampled = smote.fit_resample(X_train_processed, Y_train['ordinal'])


X_test_tensor = torch.FloatTensor(X_test_processed.values)

Y_test_multiclass = torch.LongTensor(Y_test['multi-class'].values)
Y_test_ordinal = torch.LongTensor(Y_test['ordinal'].values)
Y_test_regression = torch.FloatTensor(Y_test['regression'].values)  # Keep regression data as is

# Convert resampled data to PyTorch tensors
X_train_tensor_multiclass = torch.FloatTensor(X_train_multiclass_resampled.values)
Y_train_tensor_multiclass = torch.LongTensor(y_train_multiclass_resampled.values)

X_train_tensor_ordinal = torch.FloatTensor(X_train_ordinal_resampled.values)
Y_train_tensor_ordinal = torch.LongTensor(y_train_ordinal_resampled.values)

# Keep regression data as is
X_train_tensor_regression = torch.FloatTensor(X_train_processed.values)
Y_train_tensor_regression = torch.FloatTensor(Y_train['regression'].values).unsqueeze(1)

# Compute class weights for multi-class and ordinal
class_weights_multiclass = compute_class_weight('balanced', classes=np.unique(y_train_multiclass_resampled), y=y_train_multiclass_resampled)
class_weights_multiclass = torch.FloatTensor(class_weights_multiclass)

class_weights_ordinal = compute_class_weight('balanced', classes=np.unique(y_train_ordinal_resampled), y=y_train_ordinal_resampled)
class_weights_ordinal = torch.FloatTensor(class_weights_ordinal)

# Define the neural network model
class NeuralNetwork(nn.Module):
    def __init__(self, input_size, hidden_sizes, output_size, activation_func):
        super(NeuralNetwork, self).__init__()
        layers = []
        prev_size = input_size
        for hidden_size in hidden_sizes:
            layers.append(nn.Linear(prev_size, hidden_size))
            if activation_func == 'relu':
                layers.append(nn.ReLU())
            elif activation_func == 'tanh':
                layers.append(nn.Tanh())
            prev_size = hidden_size
        layers.append(nn.Linear(prev_size, output_size))
        self.model = nn.Sequential(*layers)

    def forward(self, x):
        return self.model(x)

# Training function
# Modify the training function to include class weights

def train_model(model, criterion, optimizer, train_loader, num_epochs, class_weights=None):
    losses = []
    for epoch in range(num_epochs):
        for inputs, targets in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            if class_weights is not None:
                # Apply class weights manually
                loss = criterion(outputs, targets)
                loss = (loss * class_weights.to(inputs.device)[targets]).mean() # Multiply loss by class weights and take mean
            else:
                loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
        losses.append(loss.item())
    return losses


# Modify the evaluation metrics

#             return accuracy, f1, precision, recall, auc


def safe_precision_score(y_true, y_pred, average='weighted'):
    with warnings.catch_warnings():
        #warnings.simplefilter("ignore")
        return precision_score(y_true, y_pred, average=average, zero_division=0)

def evaluate_model(model, X, y, task):
    model.eval()
    with torch.no_grad():
        predictions = model(X)
        if task == 'regression':
            predictions = predictions.numpy().flatten()
            y = y.flatten()
            mse = mean_squared_error(y, predictions)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y, predictions)
            r2 = r2_score(y, predictions)
            return mse, rmse, mae, r2
        else:
            _, predicted = torch.max(predictions, 1)
            predicted = predicted.numpy()
            #y = y.numpy()

            # Detailed class-wise analysis
            cm = confusion_matrix(y, predicted)
            class_accuracy = cm.diagonal() / cm.sum(axis=1)

            accuracy = accuracy_score(y, predicted)
            f1 = f1_score(y, predicted, average='weighted')
            precision = safe_precision_score(y, predicted, average='weighted')
            recall = recall_score(y, predicted, average='weighted')

            # Check for classes with no predictions
            unique_true = set(y)
            unique_pred = set(predicted)
            missing_classes = unique_true - unique_pred
            if missing_classes:
                print(f"Warning: Classes {missing_classes} were never predicted.")

            try:
                auc = roc_auc_score(y, predictions.numpy(), multi_class='ovr', average='weighted')
            except ValueError:
                auc = None  # ROC AUC score is not defined for some multi-class problems

            return accuracy, f1, precision, recall, auc, class_accuracy

# Parameter lists
learning_rate_list = [0.001, 0.01, 0.1]
activation_func_list = ['relu', 'tanh']
number_layers_list = [1, 3, 5,10]

# Results storage
results = {
    'regression': [],
    'multi-class': [],
    'ordinal': []
}




# Train and evaluate models for each parameter combination
# Modify the main training loop
# Modify the main training loop
for task in ['regression', 'multi-class', 'ordinal']:
    for lr, act_func, num_layers in product(learning_rate_list, activation_func_list, number_layers_list):
        if task == 'regression':
            input_size = X_train_tensor_regression.shape[1]
            output_size = 1
            criterion = nn.MSELoss()
            X_train = X_train_tensor_regression
            Y_train = Y_train_tensor_regression
            class_weights = None
        elif task == 'multi-class':
            input_size = X_train_tensor_multiclass.shape[1]
            output_size = len(torch.unique(Y_train_tensor_multiclass))
            criterion = nn.CrossEntropyLoss(weight=class_weights_multiclass)
            X_train = X_train_tensor_multiclass
            Y_train = Y_train_tensor_multiclass
            class_weights = class_weights_multiclass
        else:  # ordinal
            input_size = X_train_tensor_ordinal.shape[1]
            output_size = len(torch.unique(Y_train_tensor_ordinal))
            criterion = nn.CrossEntropyLoss(weight=class_weights_ordinal)
            X_train = X_train_tensor_ordinal
            Y_train = Y_train_tensor_ordinal
            class_weights = class_weights_ordinal

        hidden_sizes = [64] * num_layers
        model = NeuralNetwork(input_size, hidden_sizes, output_size, act_func)
        optimizer = optim.Adam(model.parameters(), lr=lr)

        train_dataset = TensorDataset(X_train, Y_train)
        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

        losses = train_model(model, criterion, optimizer, train_loader, num_epochs=50, class_weights=class_weights)

        # Evaluation
        if task == 'regression':
            mse, rmse, mae, r2 = evaluate_model(model, X_test_tensor, Y_test[task].values, task)
            results[task].append({
                'lr': lr,
                'activation': act_func,
                'num_layers': num_layers,
                'mse': mse,
                'rmse': rmse,
                'mae': mae,
                'r2': r2,
                'losses': losses,
                'model': model
            })
        else:
            accuracy, f1, precision, recall, auc, class_accuracy = evaluate_model(model, X_test_tensor, Y_test[task].values, task)
            results[task].append({
                'lr': lr,
                'activation': act_func,
                'num_layers': num_layers,
                'accuracy': accuracy,
                'f1': f1,
                'precision': precision,
                'recall': recall,
                'auc': auc,
                'class_accuracy': class_accuracy,
                'losses': losses,
                'model': model
            })


# Plot loss functions
for task in results:
    plt.figure(figsize=(12, 8))
    for result in results[task]:
        label = f"lr={result['lr']}, act={result['activation']}, layers={result['num_layers']}"
        plt.plot(result['losses'], label=label)
    plt.title(f'Loss Function for {task.capitalize()} Task')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.show()

# Find best models
best_models = {}
# Update the best model selection
best_models = {}
for task in results:
    if task == 'regression':
        best_model = max(results[task], key=lambda x: x['r2'])
    else:
        best_model = max(results[task], key=lambda x: x['f1'])  # Using F1-score for classification tasks
    best_models[task] = best_model

    # Plot loss function for the best model
    plt.figure(figsize=(10, 6))
    plt.plot(best_model['losses'])
    plt.title(f'Loss Function for Best {task.capitalize()} Model')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.grid(True)

    # Add text with model details
    text = f"Learning rate: {best_model['lr']}\n"
    text += f"Activation function: {best_model['activation']}\n"
    text += f"Number of layers: {best_model['num_layers']}\n"
    if task == 'regression':
        text += f"Best RMSE: {best_model['rmse']:.4f}"
    else:
        text += f"Best Accuracy: {best_model['accuracy']:.4f}"

    plt.text(0.05, 0.95, text, transform=plt.gca().transAxes, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

    plt.tight_layout()
    plt.show()

    # Generate and save predictions
    best_model['model'].eval()
    with torch.no_grad():
        if task == 'regression':
            y_pred_reg = best_model['model'](X_test_tensor).numpy().flatten()
            y_true = Y_test_regression.numpy().flatten()
        elif task == 'multi-class':
            y_pred_multi = best_model['model'](X_test_tensor).argmax(dim=1).numpy()
            y_true = Y_test_multiclass.numpy()
            print("best model multi class report")
            print(sklearn.metrics.classification_report(y_true, y_pred_multi))
        else:  # ordinal
            y_pred_ordinal = best_model['model'](X_test_tensor).argmax(dim=1).numpy()
            y_true = Y_test_ordinal.numpy()
            print("best model ordinal  report")
            print(sklearn.metrics.classification_report(y_true, y_pred_ordinal))





for task, model in best_models.items():
    print(f"\nBest model for {task}:")
    print(f"Learning rate: {model['lr']}")
    print(f"Activation function: {model['activation']}")
    print(f"Number of layers: {model['num_layers']}")
    if task == 'regression':
        print(f"MSE: {model['mse']:.4f}")
        print(f"RMSE: {model['rmse']:.4f}")
        print(f"MAE: {model['mae']:.4f}")
        print(f"R-squared: {model['r2']:.4f}")
    else:
        print(f"Accuracy: {model['accuracy']:.4f}")
        print(f"F1-score: {model['f1']:.4f}")
        print(f"Precision: {model['precision']:.4f}")
        print(f"Recall: {model['recall']:.4f}")
        if model['auc'] is not None:
            print(f"AUC: {model['auc']:.4f}")
        print("Class-wise accuracy:")
        for i, acc in enumerate(model['class_accuracy']):
            print(f"  Class {i}: {acc:.4f}")


# Plot predicted vs real values for best regression model
best_regression_model = best_models['regression']['model']
best_regression_model.eval()

with torch.no_grad():
    y_pred = best_regression_model(X_test_tensor).numpy().flatten()
    #y_pred_reg = y_pred
    y_true = Y_test_regression.numpy().flatten()

plt.figure(figsize=(10, 6))
plt.scatter(y_true, y_pred, alpha=0.5)
plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.title('Predicted vs True Values (Regression)')
plt.show()

# Print confusion matrices for best multi-class and ordinal models
for task in ['multi-class', 'ordinal']:
    best_model = best_models[task]['model']
    best_model.eval()

    with torch.no_grad():
        y_pred = best_model(X_test_tensor).argmax(dim=1).numpy()
        if task == 'multi-class':
            y_true = Y_test_multiclass.numpy()
            #y_true_multi = y_true
        else:  # ordinal
            y_true = Y_test_ordinal.numpy()
            #y_true_ordinal = y_true

    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix for {task.capitalize()} Task')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()


y_pred_all__imbalanced = pd.DataFrame({
    'y_real_real_reg': Y_test_regression.numpy().flatten(),
    'y_pred_reg': y_pred_reg,
    'y_true_multi': Y_test_multiclass.numpy(),
    'y_pred_multi': y_pred_multi,
    'y_true_ordinal': Y_test_ordinal.numpy(),
    'y_pred_ordinal': y_pred_ordinal
})